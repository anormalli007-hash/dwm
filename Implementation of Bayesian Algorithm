import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import CategoricalNB
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

# Define the column names for the car evaluation dataset
col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']

# Load the dataset
df = pd.read_csv("car_evaluation.csv", header=None, names=col_names)

print("--- Data Head ---")
print(df.head())

# --- Pre-processing: Encode Categorical Data ---
# Naive Bayes requires numerical input, so we convert categories to numbers.
encoders = {}
for column in df.columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    encoders[column] = le

# Separate the features (X) from the target variable (y)
X = df.drop('class', axis=1)
y = df['class']

# Split the data into training and testing sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# --- Model Training ---
# Initialize and train the Categorical Naive Bayes classifier
model = CategoricalNB()
model.fit(X_train, y_train)

# --- Prediction and Evaluation ---
y_pred = model.predict(X_test)

# Print the results
print("\n--- Bayesian Algorithm Results ---")
print(f"Model Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print("\nClassification Report:")
# Use the encoder to show original class names in the report
print(classification_report(y_test, y_pred, target_names=encoders['class'].classes_))
